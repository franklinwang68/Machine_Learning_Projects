{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is that more training examples can be created from our measured dataset. By taking the end of one example and beginning of the next (given that the examples share labels), a new 60 second example can be created and used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sensor_names = ['Acc_x', 'Acc_y', 'Acc_z', 'Gyr_x', 'Gyr_y', 'Gyr_z']\n",
    "label_names = [\"DNE\", \"Resting\", \"Walking\", \"Running\", \"Driving\"]\n",
    "train_suffix = '_train_1.csv'\n",
    "test_suffix = '_train_2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.loadtxt('labels_train_1.csv', dtype='int')\n",
    "data_slice_0 = np.loadtxt(sensor_names[0] + '_train_1.csv',\n",
    "                            delimiter=',')\n",
    "data = np.empty((data_slice_0.shape[0], data_slice_0.shape[1],\n",
    "                    len(sensor_names)))\n",
    "data[:, :, 0] = data_slice_0\n",
    "del data_slice_0\n",
    "for sensor_index in range(1, len(sensor_names)):\n",
    "    data[:, :, sensor_index] = np.loadtxt(\n",
    "        sensor_names[sensor_index] + '_train_1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create groups of row indices that are senquential and share the same labels\n",
    "\n",
    "index_groups = []\n",
    "temp_group = [0]\n",
    "\n",
    "for i in range(1, len(labels)):\n",
    "    if labels[i] == labels[i - 1]:\n",
    "        temp_group.append(i)\n",
    "    else:\n",
    "        index_groups.append(temp_group)\n",
    "        temp_group = [i]\n",
    "\n",
    "index_groups.append(temp_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we actually create the new rows\n",
    "num_features = len(data[0,:,0])\n",
    "\n",
    "new_training_examples = []\n",
    "new_labels = []\n",
    "\n",
    "# where to join the current and next rows\n",
    "split_point = num_features // 2\n",
    "\n",
    "for group in index_groups:\n",
    "    group_label = labels[group[0]]\n",
    "\n",
    "    # iterate through each row to create a new training example from it and the row after it (skip the final row)\n",
    "    for i in range(len(group) - 1):\n",
    "\n",
    "        idx = group[i]\n",
    "\n",
    "        curr_row = data[idx]\n",
    "        next_row = data[idx+1]\n",
    "\n",
    "        # creation of a new row\n",
    "        new_row = np.concatenate((curr_row[-split_point:], next_row[:split_point]))\n",
    "\n",
    "        new_training_examples.append(new_row)\n",
    "        new_labels.append(group_label)\n",
    "\n",
    "new_training_examples = np.array(new_training_examples)\n",
    "new_labels = np.array(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to add some noise to the generated data for addional independence\n",
    "\n",
    "# these values were eyeballed while looking at the \n",
    "acc_noise_magnitude = 0.0\n",
    "gyr_noise_magnitude = 0.0\n",
    "\n",
    "\n",
    "\n",
    "acc_part = new_training_examples[:, :, :3]\n",
    "gyr_part = new_training_examples[:, ::, 3:]\n",
    "\n",
    "acc_noise = acc_noise_magnitude * np.random.randn(*acc_part.shape)\n",
    "gyr_noise = gyr_noise_magnitude * np.random.randn(*gyr_part.shape)\n",
    "\n",
    "acc_part = acc_part + acc_noise\n",
    "gyr_part = gyr_part + gyr_noise\n",
    "\n",
    "noisy_new_training_examples = np.concatenate([acc_part, gyr_part], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the generated data into a similar file format\n",
    "\n",
    "np.savetxt(\"generated_labels_train_1.csv\", new_labels, delimiter=\",\", fmt=\"%d\")\n",
    "\n",
    "num_channels = len(data[0,0,:])\n",
    "\n",
    "for i in range(num_channels):\n",
    "    file_name = 'generated_' + sensor_names[i] + '_train_1.csv'\n",
    "    np.savetxt(file_name, noisy_new_training_examples[:,:,i], delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csds340",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
